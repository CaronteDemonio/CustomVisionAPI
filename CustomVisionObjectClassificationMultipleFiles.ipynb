{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to upload multiple files for an object classification project using Custom Vision from Microsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample code will let you upload multiple image files, and their related tags, in one batch. It can be useful when you have to use multiple files for your object classification project.\n",
    "\n",
    "Let's start by creating the project. Remember to replace the keys with your own keys! You might also want to change the project name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry\n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = \"<INSERT YOUR TRAINING KEY>\"\n",
    "prediction_key = \"<INSERT YOUR PREDICTION KEY>\"\n",
    "\n",
    "trainer = training_api.TrainingApi(training_key)\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"Object Classification Multiple Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the tags. I am using only two tags, but of course you can create as many as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two tags in the new project\n",
    "Up_tag = trainer.create_tag(project.id, \"Up\")\n",
    "Down_tag = trainer.create_tag(project.id, \"Down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am reading the images from a directory - again, remember to change the directory with the one you will use - and then I am uploading the images into the Custom Vision service, adding the related tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.vision.customvision.training.models.image_create_summary_py3.ImageCreateSummary at 0x2488da794a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the directory with the one you will be using\n",
    "Up_dir = \"Images\\\\Train\\\\Up\"\n",
    "List_of_images = []\n",
    "List_of_tags = []\n",
    "# Upload all the images in the folder with the same 'Up' tag\n",
    "for image in os.listdir(os.fsencode(Up_dir)):\n",
    "    with open(Up_dir + \"\\\\\" + os.fsdecode(image), mode=\"rb\") as img_data: \n",
    "        List_of_images.append(ImageFileCreateEntry(name=os.path.basename(image), contents = img_data.read()))\n",
    "        List_of_tags.append(Up_tag.id)\n",
    "trainer.create_images_from_files(project.id, List_of_images, tag_ids = List_of_tags)\n",
    "\n",
    "# Change the directory with the one you will be using\n",
    "Down_dir = \"Images\\\\Train\\\\Down\"\n",
    "List_of_images = []\n",
    "List_of_tags = []\n",
    "# Upload all the images in the folder with the same 'Down' tag\n",
    "for image in os.listdir(os.fsencode(Down_dir)):\n",
    "    with open(Down_dir + \"\\\\\" + os.fsdecode(image), mode=\"rb\") as img_data: \n",
    "        List_of_images.append(ImageFileCreateEntry(name=os.path.basename(image), contents = img_data.read()))\n",
    "        List_of_tags.append(Down_tag.id)\n",
    "trainer.create_images_from_files(project.id, List_of_images, tag_ids = List_of_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model. The code is exactly the same provided in the sample code documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Make it the default project endpoint\n",
    "trainer.update_iteration(project.id, iteration.id, is_default=True)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's predict the tags of some images. The only difference here from the sample code provided in the service is that here I am using the \"no store\" API, which does not store the predicted image in the service. You can change it with the standard API call if you need to store your predicted images within the Custom Vision service.\n",
    "\n",
    "Unfortunately there is not currently an API to predict multiple images with one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUp: 87.55%\n",
      "\tDown: 3.57%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = prediction_endpoint.PredictionEndpoint(prediction_key)\n",
    "\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(\"Images\\\\test\\\\200000.png\", mode=\"rb\") as test_data:\n",
    "     results = predictor.predict_image_with_no_store(project.id, test_data, iteration.id)\n",
    "\n",
    "# Display the results.\n",
    "for prediction in results.predictions:\n",
    "    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
